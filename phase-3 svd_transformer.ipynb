{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98ce7b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU] Using: NVIDIA GeForce RTX 3060 Laptop GPU (SMs=30)\n",
      "[INFO] Original class counts: Counter({np.int32(0): 3990, np.int32(1): 1852})\n",
      "[INFO] After oversampling: Counter({np.int32(1): 3990, np.int32(0): 3990})\n",
      "Epoch 1/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 2/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 3/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 4/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 5/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 6/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 7/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 8/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 9/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 10/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 11/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 12/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 13/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 14/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 15/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 16/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 17/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 18/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 19/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 20/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 21/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 22/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 23/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 24/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 25/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 26/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 27/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 28/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 29/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 30/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 31/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 32/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 33/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 34/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 35/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 36/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 37/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 38/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 39/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 40/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 41/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 42/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 43/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 44/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 45/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 46/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 47/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 48/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 49/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "Epoch 50/50 - Loss: 0.6931 - Acc: 50.00%\n",
      "[INFO] Training finished in 3.55s\n",
      "[RESULT] Total Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Trial -3: SVD-based embeddings with GPU Transformer classifier\n",
    "\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "assert cp.cuda.runtime.getDeviceCount() > 0, \"No CUDA GPU detected!\"\n",
    "with cp.cuda.Device(0) as dev:\n",
    "    props = cp.cuda.runtime.getDeviceProperties(dev.id)\n",
    "    print(f\"[GPU] Using: {props['name'].decode()} (SMs={props['multiProcessorCount']})\")\n",
    "\n",
    "#  Text Preprocessing \n",
    "def clean_text(s: str) -> str:\n",
    "    \"\"\"Lowercase text, remove special characters, normalize spaces.\"\"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^\\w\\s$]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    \"\"\"Build vocabulary and mapping from word to index.\"\"\"\n",
    "    cleaned = [clean_text(s) for s in sentences]\n",
    "    all_tokens = \" \".join(cleaned).split()\n",
    "    vocab = sorted(set(all_tokens))\n",
    "    word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "    return cleaned, all_tokens, word_to_idx\n",
    "\n",
    "#  GPU Kernels -\n",
    "\n",
    "matmul_kernel_code = r'''\n",
    "extern \"C\" __global__\n",
    "void matmul_kernel(const float* A, const float* B, float* C, int M, int K, int N){\n",
    "    int row = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    int col = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(row < M && col < N){\n",
    "        float sum = 0.0f;\n",
    "        for(int k = 0; k < K; ++k){\n",
    "            sum += A[row*K + k] * B[k*N + col];\n",
    "        }\n",
    "        C[row*N + col] = sum;\n",
    "    }\n",
    "}\n",
    "'''\n",
    "matmul_kernel = cp.RawKernel(matmul_kernel_code, 'matmul_kernel')\n",
    "\n",
    "def matmul(A, B):\n",
    "    M, K = A.shape\n",
    "    K2, N = B.shape\n",
    "    assert K == K2\n",
    "    C = cp.zeros((M, N), dtype=cp.float32)\n",
    "    block = (16,16,1)\n",
    "    grid  = ((N + block[0]-1)//block[0], (M + block[1]-1)//block[1], 1)\n",
    "    matmul_kernel(grid, block, (A,B,C,M,K,N))\n",
    "    return C\n",
    "\n",
    "softmax_kernel_code = r'''\n",
    "extern \"C\" __global__\n",
    "void row_softmax(float* X, int M, int N){\n",
    "    int row = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(row < M){\n",
    "        float max_val = -1e20f;\n",
    "        for(int j=0;j<N;j++){\n",
    "            float v = X[row*N + j];\n",
    "            max_val = v>max_val?v:max_val;\n",
    "        }\n",
    "        float sum_exp = 0.0f;\n",
    "        for(int j=0;j<N;j++){\n",
    "            float e = __expf(X[row*N+j]-max_val);\n",
    "            X[row*N+j] = e;\n",
    "            sum_exp += e;\n",
    "        }\n",
    "        float inv = 1.0f / sum_exp;\n",
    "        for(int j=0;j<N;j++) X[row*N+j] *= inv;\n",
    "    }\n",
    "}\n",
    "'''\n",
    "softmax_kernel = cp.RawKernel(softmax_kernel_code, 'row_softmax')\n",
    "\n",
    "def softmax(X):\n",
    "    M, N = X.shape\n",
    "    block = (128,1,1)\n",
    "    grid  = ((M+block[0]-1)//block[0],1,1)\n",
    "    softmax_kernel(grid, block, (X,M,N))\n",
    "    return X\n",
    "\n",
    "relu_kernel_code = r'''\n",
    "extern \"C\" __global__\n",
    "void relu(float* X, int MN){\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(idx < MN){\n",
    "        float v = X[idx];\n",
    "        X[idx] = v>0.0f?v:0.0f;\n",
    "    }\n",
    "}\n",
    "'''\n",
    "relu_kernel = cp.RawKernel(relu_kernel_code,'relu')\n",
    "\n",
    "def relu(X):\n",
    "    MN = X.size\n",
    "    block = (256,1,1)\n",
    "    grid  = ((MN+block[0]-1)//block[0],1,1)\n",
    "    relu_kernel(grid, block, (X,MN))\n",
    "    return X\n",
    "\n",
    "#  Co-occurrence & PPMI \n",
    "cooc_kernel_code = r'''\n",
    "extern \"C\" __global__\n",
    "void cooc_kernel(const int* tokens, float* co_matrix, int len, int window, int vocab_size){\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(idx < len){\n",
    "        int target = tokens[idx];\n",
    "        for(int offset=-window;offset<=window;offset++){\n",
    "            int j = idx+offset;\n",
    "            if(j>=0 && j<len && j!=idx){\n",
    "                int context = tokens[j];\n",
    "                atomicAdd(&co_matrix[target*vocab_size+context],1.0f);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "cooc_kernel = cp.RawKernel(cooc_kernel_code,'cooc_kernel')\n",
    "\n",
    "def build_co_matrix(tokens, word_to_idx, window=2):\n",
    "    token_ids = cp.asarray([word_to_idx[t] for t in tokens], dtype=cp.int32)\n",
    "    vocab_size = len(word_to_idx)\n",
    "    co_matrix = cp.zeros((vocab_size,vocab_size), dtype=cp.float32)\n",
    "    block = (256,1,1)\n",
    "    grid  = ((token_ids.size+block[0]-1)//block[0],1,1)\n",
    "    cooc_kernel(grid, block, (token_ids,co_matrix,token_ids.size,window,vocab_size))\n",
    "    return co_matrix\n",
    "\n",
    "ppmi_kernel_code = r'''\n",
    "extern \"C\" __global__\n",
    "void ppmi_kernel(const float* co_matrix, float* ppmi, const float* row_sum, const float* col_sum, float total, int N){\n",
    "    int j = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int i = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    if(i<N && j<N){\n",
    "        float cij = co_matrix[i*N+j];\n",
    "        if(cij>0.0f){\n",
    "            float pij = cij/total;\n",
    "            float pi = row_sum[i]/total;\n",
    "            float pj = col_sum[j]/total;\n",
    "            float val = logf(pij/(pi*pj));\n",
    "            ppmi[i*N+j] = val>0.0f?val:0.0f;\n",
    "        }else{\n",
    "            ppmi[i*N+j] = 0.0f;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "ppmi_kernel = cp.RawKernel(ppmi_kernel_code,'ppmi_kernel')\n",
    "\n",
    "def compute_ppmi(co_matrix):\n",
    "    N = co_matrix.shape[0]\n",
    "    row_sum = cp.sum(co_matrix, axis=1).astype(cp.float32)\n",
    "    col_sum = cp.sum(co_matrix, axis=0).astype(cp.float32)\n",
    "    total   = cp.sum(co_matrix).astype(cp.float32)\n",
    "    ppmi = cp.zeros_like(co_matrix,dtype=cp.float32)\n",
    "    block = (16,16,1)\n",
    "    grid  = ((N+block[0]-1)//block[0],(N+block[1]-1)//block[1],1)\n",
    "    ppmi_kernel(grid, block, (co_matrix,ppmi,row_sum,col_sum,float(total),N))\n",
    "    return ppmi\n",
    "\n",
    "#  SVD Embeddings \n",
    "def svd_embeddings(ppmi, dim=10, iters=30):\n",
    "    N = ppmi.shape[0]\n",
    "    U = cp.random.randn(N, dim).astype(cp.float32)\n",
    "    for _ in range(iters):\n",
    "        U = matmul(ppmi, matmul(ppmi.T,U))\n",
    "        norms = cp.sqrt(cp.sum(U*U, axis=0, keepdims=True)+1e-8)\n",
    "        U /= norms\n",
    "    return U\n",
    "\n",
    "def sentence_to_emb(sentence, word_to_idx, embeddings):\n",
    "    words = sentence.split()\n",
    "    idxs = [word_to_idx[w] for w in words if w in word_to_idx]\n",
    "    if len(idxs)==0:\n",
    "        return cp.zeros((embeddings.shape[1],), dtype=cp.float32)\n",
    "    return cp.mean(embeddings[idxs], axis=0)\n",
    "\n",
    "#  Transformer Classifier \n",
    "class TransformerGPU:\n",
    "    def __init__(self,input_dim,n_classes,d_model=32):\n",
    "        self.W_embed = cp.random.randn(input_dim,d_model).astype(cp.float32)*0.1\n",
    "        self.W_Q = cp.random.randn(d_model,d_model).astype(cp.float32)*0.1\n",
    "        self.W_K = cp.random.randn(d_model,d_model).astype(cp.float32)*0.1\n",
    "        self.W_V = cp.random.randn(d_model,d_model).astype(cp.float32)*0.1\n",
    "        self.W_ff= cp.random.randn(d_model,d_model).astype(cp.float32)*0.1\n",
    "        self.b_ff= cp.zeros(d_model,dtype=cp.float32)\n",
    "        self.W_out = cp.random.randn(d_model,n_classes).astype(cp.float32)*0.1\n",
    "        self.b_out = cp.zeros(n_classes,dtype=cp.float32)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self,X):\n",
    "        X_emb = matmul(X,self.W_embed)\n",
    "        Q = matmul(X_emb,self.W_Q)\n",
    "        K = matmul(X_emb,self.W_K)\n",
    "        V = matmul(X_emb,self.W_V)\n",
    "        scores = matmul(Q,K.T)/cp.sqrt(cp.float32(self.d_model))\n",
    "        attention = softmax(scores.copy())\n",
    "        out = matmul(attention,V)\n",
    "        X_res = X_emb + out\n",
    "        mean = cp.mean(X_res, axis=1, keepdims=True)\n",
    "        std  = cp.std(X_res, axis=1, keepdims=True)+1e-6\n",
    "        X_norm = (X_res-mean)/std\n",
    "        FF = matmul(X_norm,self.W_ff)+self.b_ff\n",
    "        FF = relu(FF)\n",
    "        X_ff = X_norm + FF\n",
    "        logits = matmul(X_ff,self.W_out)+self.b_out\n",
    "        return logits, X_ff\n",
    "\n",
    "    def update(self,X_ff,y,logits,lr=0.05):\n",
    "        exp_logits = cp.exp(logits - cp.max(logits,axis=1,keepdims=True))\n",
    "        probs = exp_logits/cp.sum(exp_logits,axis=1,keepdims=True)\n",
    "        probs[cp.arange(y.size),y] -=1.0\n",
    "        probs /= y.size\n",
    "        self.W_out -= lr*matmul(X_ff.T,probs)\n",
    "        self.b_out -= lr*cp.sum(probs,axis=0)\n",
    "\n",
    "def cross_entropy(logits,y):\n",
    "    max_logits = cp.max(logits, axis=1, keepdims=True)\n",
    "    log_probs = logits - max_logits - cp.log(cp.sum(cp.exp(logits-max_logits),axis=1,keepdims=True))\n",
    "    return -cp.mean(log_probs[cp.arange(y.size),y])\n",
    "\n",
    "\n",
    "def oversample_gpu(X,y):\n",
    "    counts = Counter(cp.asnumpy(y))\n",
    "    max_count = max(counts.values())\n",
    "    X_new, y_new = [X],[y]\n",
    "    for label in counts:\n",
    "        idxs = cp.where(y==label)[0]\n",
    "        n_add = max_count - counts[label]\n",
    "        if n_add>0:\n",
    "            reps = cp.random.choice(idxs,n_add)\n",
    "            X_new.append(X[reps])\n",
    "            y_new.append(y[reps])\n",
    "    return cp.concatenate(X_new,axis=0), cp.concatenate(y_new,axis=0)\n",
    "\n",
    "def train_gpu(sentences, labels, epochs=100, lr=0.1, embedding_dim=32):\n",
    "    start_time = time.time()\n",
    "    cleaned, all_tokens, word_to_idx = build_vocab(sentences)\n",
    "    co_matrix = build_co_matrix(all_tokens, word_to_idx)\n",
    "    ppmi = compute_ppmi(co_matrix)\n",
    "    embeddings = svd_embeddings(ppmi, dim=embedding_dim)\n",
    "\n",
    "    X = cp.stack([sentence_to_emb(s, word_to_idx, embeddings) for s in cleaned])\n",
    "    y = cp.asarray(labels,dtype=cp.int32)\n",
    "\n",
    "    print(\"[INFO] Original class counts:\", Counter(cp.asnumpy(y)))\n",
    "    X, y = oversample_gpu(X, y)\n",
    "    print(\"[INFO] After oversampling:\", Counter(cp.asnumpy(y)))\n",
    "\n",
    "    n_classes = len(set(cp.asnumpy(y)))\n",
    "    model = TransformerGPU(X.shape[1], n_classes, d_model=embedding_dim)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        perm = cp.random.permutation(X.shape[0])\n",
    "        X_shuff = X[perm]\n",
    "        y_shuff = y[perm]\n",
    "\n",
    "        logits, X_ff = model.forward(X_shuff)\n",
    "        loss = cross_entropy(logits, y_shuff)\n",
    "        model.update(X_ff, y_shuff, logits, lr)\n",
    "\n",
    "        pred = cp.argmax(logits, axis=1)\n",
    "        acc = cp.mean((pred==y_shuff).astype(cp.float32))\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {float(loss):.4f} - Acc: {float(acc)*100:.2f}%\")\n",
    "\n",
    "    logits, _ = model.forward(X)\n",
    "    pred = cp.argmax(logits, axis=1)\n",
    "    total_acc = cp.mean((pred==y).astype(cp.float32))\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"[INFO] Training finished in {total_time:.2f}s\")\n",
    "    print(f\"[RESULT] Total Accuracy: {float(total_acc)*100:.2f}%\")\n",
    "    return model, embeddings, word_to_idx\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    df = pd.read_csv(r\"C:\\Users\\Pavani Akshaya\\Downloads\\fin_data_1.csv\")\n",
    "    sentences = df[\"Sentence\"].astype(str).tolist()\n",
    "    lab = df[\"Sentiment\"].astype(str).str.lower().str.strip()\n",
    "    label_map = {\"positive\":1,\"neg\":0,\"negative\":0,\"pos\":1,\"1\":1,\"0\":0}\n",
    "    labels = [label_map.get(x,1 if x in (\"1\",\"true\") else 0) for x in lab]\n",
    "\n",
    "    model, embeddings, word_to_idx = train_gpu(\n",
    "        sentences, labels, epochs=50, lr=0.01, embedding_dim=32)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
