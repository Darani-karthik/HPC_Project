{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal CuPy dot] Time: 1.1330 seconds\n",
      "[CUDA tiled kernel] Time: 0.1929 seconds\n",
      "Difference between normal and CUDA tiled: 0.005127\n",
      "\n",
      "Sample output (top-left 5x5 block):\n",
      "[[1034.8945  1030.321   1047.7356  1021.0392  1032.5448 ]\n",
      " [1030.0343  1030.151   1041.3389  1019.707   1029.7284 ]\n",
      " [1024.3102  1027.2953  1041.6548  1028.2279  1029.5394 ]\n",
      " [1019.1637  1020.75757 1021.829   1011.0303  1017.7923 ]\n",
      " [1018.0107  1008.7152  1039.5358  1015.09216 1020.16864]]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import time\n",
    "N = 4096  \n",
    "TILE = 16\n",
    "\n",
    "# Allocate large random matrices\n",
    "A = cp.random.rand(N, N, dtype=cp.float32)\n",
    "B = cp.random.rand(N, N, dtype=cp.float32)\n",
    "\n",
    "# Reference CuPy dot product (cuBLAS)\n",
    "start = time.time()\n",
    "C_normal = cp.dot(A, B)\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "end = time.time()\n",
    "time_normal = end - start\n",
    "print(f\"[Normal CuPy dot] Time: {time_normal:.4f} seconds\")\n",
    "\n",
    "# CUDA tiled kernel\n",
    "kernel_code = f'''\n",
    "extern \"C\" __global__\n",
    "void matmul_tiled(const float* A, const float* B, float* C, int N) {{\n",
    "    __shared__ float sA[{TILE}][{TILE}];\n",
    "    __shared__ float sB[{TILE}][{TILE}];\n",
    "    \n",
    "    int row = blockIdx.y * {TILE} + threadIdx.y;\n",
    "    int col = blockIdx.x * {TILE} + threadIdx.x;\n",
    "    \n",
    "    float value = 0.0f;\n",
    "    \n",
    "    for (int t = 0; t < (N + {TILE} - 1)/{TILE}; t++) {{\n",
    "        int tiled_row = row;\n",
    "        int tiled_col = t*{TILE} + threadIdx.x;\n",
    "        if(tiled_row < N && tiled_col < N) sA[threadIdx.y][threadIdx.x] = A[tiled_row*N + tiled_col];\n",
    "        else sA[threadIdx.y][threadIdx.x] = 0.0f;\n",
    "        \n",
    "        tiled_row = t*{TILE} + threadIdx.y;\n",
    "        tiled_col = col;\n",
    "        if(tiled_row < N && tiled_col < N) sB[threadIdx.y][threadIdx.x] = B[tiled_row*N + tiled_col];\n",
    "        else sB[threadIdx.y][threadIdx.x] = 0.0f;\n",
    "        \n",
    "        __syncthreads();\n",
    "        \n",
    "        for(int k=0; k<{TILE}; k++) value += sA[threadIdx.y][k] * sB[k][threadIdx.x];\n",
    "        __syncthreads();\n",
    "    }}\n",
    "    \n",
    "    if(row < N && col < N) C[row*N + col] = value;\n",
    "}}\n",
    "'''\n",
    "\n",
    "matmul_kernel = cp.RawKernel(kernel_code, 'matmul_tiled')\n",
    "\n",
    "C_cuda = cp.zeros((N, N), dtype=cp.float32)\n",
    "\n",
    "threads_per_block = (TILE, TILE)\n",
    "blocks_per_grid = ((N + TILE - 1)//TILE, (N + TILE - 1)//TILE)\n",
    "\n",
    "start = time.time()\n",
    "matmul_kernel(blocks_per_grid, threads_per_block, (A, B, C_cuda, N))\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "end = time.time()\n",
    "time_cuda = end - start\n",
    "print(f\"[CUDA tiled kernel] Time: {time_cuda:.4f} seconds\")\n",
    "\n",
    "# Difference check\n",
    "diff = cp.max(cp.abs(C_normal - C_cuda))\n",
    "print(f\"Difference between normal and CUDA tiled: {diff:.6f}\")\n",
    "\n",
    "# Show part of result (top-left 5x5 block only)\n",
    "print(\"\\nSample output (top-left 5x5 block):\")\n",
    "print(C_cuda[:5, :5].get())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
